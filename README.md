# llm-from-scratch

This repository demonstrates how to build a simple tokenizer and convert text into token IDs using Python. The main code is provided in a Jupyter Notebook for easy step-by-step learning.

## Project Structure

- `tokenize.ipynb`: Example notebook showing how to split text into tokens, handle punctuation, create a vocabulary, and convert tokens to token IDs.
- `README.md`: Project description and usage instructions.

## Usage

1. Open `tokenize.ipynb` in Jupyter Notebook or VS Code.
2. Run each cell to see how text is tokenized and converted to token IDs.

## Features

- Uses `re.split` to tokenize text by whitespace and punctuation.
- Builds a vocabulary from the tokens.
- Converts tokens to token IDs for further processing.

## Suitable For

- Beginners who want to understand how tokenization works.
- Anyone interested in building basic NLP pipelines or LLM components from scratch.
